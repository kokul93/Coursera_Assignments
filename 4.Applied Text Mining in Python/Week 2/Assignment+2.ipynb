{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher',\n",
       " '--',\n",
       " 'threadbare',\n",
       " 'in',\n",
       " 'coat',\n",
       " ',',\n",
       " 'heart',\n",
       " ',',\n",
       " 'body',\n",
       " ',',\n",
       " 'and',\n",
       " 'brain',\n",
       " ';',\n",
       " 'I',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'ever',\n",
       " 'dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and',\n",
       " 'grammars',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'queer',\n",
       " 'handkerchief',\n",
       " ',',\n",
       " 'mockingly',\n",
       " 'embellished',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'gay',\n",
       " 'flags',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'known',\n",
       " 'nations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'He',\n",
       " 'loved',\n",
       " 'to',\n",
       " 'dust',\n",
       " 'his',\n",
       " 'old',\n",
       " 'grammars',\n",
       " ';',\n",
       " 'it',\n",
       " 'somehow',\n",
       " 'mildly',\n",
       " 'reminded',\n",
       " 'him',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mortality',\n",
       " '.',\n",
       " '``',\n",
       " 'While',\n",
       " 'you',\n",
       " 'take',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'to',\n",
       " 'school',\n",
       " 'others',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'teach',\n",
       " 'them',\n",
       " 'by',\n",
       " 'what',\n",
       " 'name',\n",
       " 'a',\n",
       " 'whale-fish',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'called',\n",
       " 'in',\n",
       " 'our',\n",
       " 'tongue',\n",
       " 'leaving',\n",
       " 'out',\n",
       " ',',\n",
       " 'through',\n",
       " 'ignorance',\n",
       " ',',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'H',\n",
       " ',',\n",
       " 'which',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'maketh',\n",
       " 'the',\n",
       " 'signification',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " ',',\n",
       " 'you',\n",
       " 'deliver',\n",
       " 'that',\n",
       " 'which',\n",
       " 'is',\n",
       " 'not',\n",
       " 'true',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " \"''\",\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'Sw.',\n",
       " 'and',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'This',\n",
       " 'animal',\n",
       " 'is',\n",
       " 'named',\n",
       " 'from',\n",
       " 'roundness',\n",
       " 'or',\n",
       " 'rolling',\n",
       " ';',\n",
       " 'for',\n",
       " 'in',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'is',\n",
       " 'arched',\n",
       " 'or',\n",
       " 'vaulted',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " \"WEBSTER'S\",\n",
       " 'DICTIONARY',\n",
       " \"''\",\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'It',\n",
       " 'is',\n",
       " 'more',\n",
       " 'immediately',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Dut',\n",
       " '.',\n",
       " 'and',\n",
       " 'Ger',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A.S.',\n",
       " 'WALW-IAN',\n",
       " ',',\n",
       " 'to',\n",
       " 'roll',\n",
       " ',',\n",
       " 'to',\n",
       " 'wallow',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'S\",\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO-SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE-NUEE-NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE-NUEE-NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Sub-Sub-Librarian',\n",
       " ')',\n",
       " '.',\n",
       " 'It',\n",
       " 'will',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'that',\n",
       " 'this',\n",
       " 'mere',\n",
       " 'painstaking',\n",
       " 'burrower',\n",
       " 'and',\n",
       " 'grub-worm',\n",
       " 'of',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub-Sub',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'through',\n",
       " 'the',\n",
       " 'long',\n",
       " 'Vaticans',\n",
       " 'and',\n",
       " 'street-stalls',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " ',',\n",
       " 'picking',\n",
       " 'up',\n",
       " 'whatever',\n",
       " 'random',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'whales',\n",
       " 'he',\n",
       " 'could',\n",
       " 'anyways',\n",
       " 'find',\n",
       " 'in',\n",
       " 'any',\n",
       " 'book',\n",
       " 'whatsoever',\n",
       " ',',\n",
       " 'sacred',\n",
       " 'or',\n",
       " 'profane',\n",
       " '.',\n",
       " 'Therefore',\n",
       " 'you',\n",
       " 'must',\n",
       " 'not',\n",
       " ',',\n",
       " 'in',\n",
       " 'every',\n",
       " 'case',\n",
       " 'at',\n",
       " 'least',\n",
       " ',',\n",
       " 'take',\n",
       " 'the',\n",
       " 'higgledy-piggledy',\n",
       " 'whale',\n",
       " 'statements',\n",
       " ',',\n",
       " 'however',\n",
       " 'authentic',\n",
       " ',',\n",
       " 'in',\n",
       " 'these',\n",
       " 'extracts',\n",
       " ',',\n",
       " 'for',\n",
       " 'veritable',\n",
       " 'gospel',\n",
       " 'cetology',\n",
       " '.',\n",
       " 'Far',\n",
       " 'from',\n",
       " 'it',\n",
       " '.',\n",
       " 'As',\n",
       " 'touching',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'authors',\n",
       " 'generally',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'poets',\n",
       " 'here',\n",
       " 'appearing',\n",
       " ',',\n",
       " 'these',\n",
       " 'extracts',\n",
       " 'are',\n",
       " 'solely',\n",
       " 'valuable',\n",
       " 'or',\n",
       " 'entertaining',\n",
       " ',',\n",
       " 'as',\n",
       " 'affording',\n",
       " 'a',\n",
       " 'glancing',\n",
       " 'bird',\n",
       " \"'s\",\n",
       " 'eye',\n",
       " 'view',\n",
       " 'of',\n",
       " 'what',\n",
       " 'has',\n",
       " 'been',\n",
       " 'promiscuously',\n",
       " 'said',\n",
       " ',',\n",
       " 'thought',\n",
       " ',',\n",
       " 'fancied',\n",
       " ',',\n",
       " 'and',\n",
       " 'sung',\n",
       " 'of',\n",
       " 'Leviathan',\n",
       " ',',\n",
       " 'by',\n",
       " 'many',\n",
       " 'nations',\n",
       " 'and',\n",
       " 'generations',\n",
       " ',',\n",
       " 'including',\n",
       " 'our',\n",
       " 'own',\n",
       " '.',\n",
       " 'So',\n",
       " 'fare',\n",
       " 'thee',\n",
       " 'well',\n",
       " ',',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub-Sub',\n",
       " ',',\n",
       " 'whose',\n",
       " 'commentator',\n",
       " 'I',\n",
       " 'am',\n",
       " '.',\n",
       " 'Thou',\n",
       " 'belongest',\n",
       " 'to',\n",
       " 'that',\n",
       " 'hopeless',\n",
       " ',',\n",
       " 'sallow',\n",
       " 'tribe',\n",
       " 'which',\n",
       " 'no',\n",
       " 'wine',\n",
       " 'of',\n",
       " 'this',\n",
       " 'world',\n",
       " 'will',\n",
       " 'ever',\n",
       " 'warm',\n",
       " ';',\n",
       " 'and',\n",
       " 'for',\n",
       " 'whom',\n",
       " 'even',\n",
       " 'Pale',\n",
       " 'Sherry',\n",
       " 'would',\n",
       " 'be',\n",
       " 'too',\n",
       " 'rosy-strong',\n",
       " ';',\n",
       " 'but',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'one',\n",
       " 'sometimes',\n",
       " 'loves',\n",
       " 'to',\n",
       " 'sit',\n",
       " ',',\n",
       " 'and',\n",
       " 'feel',\n",
       " 'poor-devilish',\n",
       " ',',\n",
       " 'too',\n",
       " ';',\n",
       " 'and',\n",
       " 'grow',\n",
       " 'convivial',\n",
       " 'upon',\n",
       " 'tears',\n",
       " ';',\n",
       " 'and',\n",
       " 'say',\n",
       " 'to',\n",
       " 'them',\n",
       " 'bluntly',\n",
       " ',',\n",
       " 'with',\n",
       " 'full',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'empty',\n",
       " 'glasses',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'not',\n",
       " 'altogether',\n",
       " 'unpleasant',\n",
       " 'sadness',\n",
       " '--',\n",
       " 'Give',\n",
       " 'it',\n",
       " 'up',\n",
       " ',',\n",
       " 'Sub-Subs',\n",
       " '!',\n",
       " 'For',\n",
       " 'by',\n",
       " 'how',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'pains',\n",
       " 'ye',\n",
       " 'take',\n",
       " 'to',\n",
       " 'please',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'by',\n",
       " 'so',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'ye',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'go',\n",
       " 'thankless',\n",
       " '!',\n",
       " 'Would',\n",
       " 'that',\n",
       " 'I',\n",
       " 'could',\n",
       " 'clear',\n",
       " 'out',\n",
       " 'Hampton',\n",
       " 'Court',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Tuileries',\n",
       " 'for',\n",
       " 'ye',\n",
       " '!',\n",
       " 'But',\n",
       " 'gulp',\n",
       " 'down',\n",
       " 'your',\n",
       " 'tears',\n",
       " 'and',\n",
       " 'hie',\n",
       " 'aloft',\n",
       " 'to',\n",
       " 'the',\n",
       " 'royal-mast',\n",
       " 'with',\n",
       " 'your',\n",
       " 'hearts',\n",
       " ';',\n",
       " 'for',\n",
       " 'your',\n",
       " 'friends',\n",
       " 'who',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'before',\n",
       " 'are',\n",
       " 'clearing',\n",
       " 'out',\n",
       " 'the',\n",
       " 'seven-storied',\n",
       " 'heavens',\n",
       " ',',\n",
       " 'and',\n",
       " 'making',\n",
       " 'refugees',\n",
       " 'of',\n",
       " 'long-pampered',\n",
       " 'Gabriel',\n",
       " ',',\n",
       " 'Michael',\n",
       " ',',\n",
       " 'and',\n",
       " 'Raphael',\n",
       " ',',\n",
       " 'against',\n",
       " 'your',\n",
       " 'coming',\n",
       " '.',\n",
       " 'Here',\n",
       " 'ye',\n",
       " 'strike',\n",
       " 'but',\n",
       " 'splintered',\n",
       " 'hearts',\n",
       " 'together',\n",
       " '--',\n",
       " 'there',\n",
       " ',',\n",
       " 'ye',\n",
       " 'shall',\n",
       " 'strike',\n",
       " 'unsplinterable',\n",
       " 'glasses',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '``',\n",
       " 'And',\n",
       " 'God',\n",
       " 'created',\n",
       " 'great',\n",
       " 'whales',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '``',\n",
       " 'Leviathan',\n",
       " 'maketh',\n",
       " 'a',\n",
       " 'path',\n",
       " 'to',\n",
       " 'shine',\n",
       " 'after',\n",
       " 'him',\n",
       " ';',\n",
       " 'One',\n",
       " 'would',\n",
       " 'think',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'to',\n",
       " 'be',\n",
       " 'hoary',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '``',\n",
       " 'Now',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'had',\n",
       " 'prepared',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fish',\n",
       " 'to',\n",
       " 'swallow',\n",
       " 'up',\n",
       " 'Jonah',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '``',\n",
       " 'There',\n",
       " 'go',\n",
       " 'the',\n",
       " 'ships',\n",
       " ';',\n",
       " 'there',\n",
       " 'is',\n",
       " 'that',\n",
       " 'Leviathan',\n",
       " 'whom',\n",
       " 'thou',\n",
       " 'hast',\n",
       " 'made',\n",
       " 'to',\n",
       " 'play',\n",
       " 'therein',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '``',\n",
       " 'In',\n",
       " 'that',\n",
       " 'day',\n",
       " ',',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'with',\n",
       " 'his',\n",
       " 'sore',\n",
       " ',',\n",
       " 'and',\n",
       " 'great',\n",
       " ',',\n",
       " 'and',\n",
       " 'strong',\n",
       " 'sword',\n",
       " ',',\n",
       " 'shall',\n",
       " 'punish',\n",
       " 'Leviathan',\n",
       " 'the',\n",
       " 'piercing',\n",
       " 'serpent',\n",
       " ',',\n",
       " 'even',\n",
       " 'Leviathan',\n",
       " 'that',\n",
       " 'crooked',\n",
       " 'serpent',\n",
       " ';',\n",
       " 'and',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'slay',\n",
       " 'the',\n",
       " 'dragon',\n",
       " 'that',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sea',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " \"''\",\n",
       " 'And',\n",
       " 'what',\n",
       " 'thing',\n",
       " 'soever',\n",
       " 'besides',\n",
       " 'cometh',\n",
       " 'within',\n",
       " 'the',\n",
       " 'chaos',\n",
       " 'of',\n",
       " 'this',\n",
       " 'monster',\n",
       " \"'s\",\n",
       " 'mouth',\n",
       " ',',\n",
       " 'be',\n",
       " 'it',\n",
       " 'beast',\n",
       " ',',\n",
       " 'boat',\n",
       " ',',\n",
       " 'or',\n",
       " 'stone',\n",
       " ',',\n",
       " 'down',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'all',\n",
       " 'incontinently',\n",
       " 'that',\n",
       " 'foul',\n",
       " 'great',\n",
       " 'swallow',\n",
       " 'of',\n",
       " 'his',\n",
       " ',',\n",
       " 'and',\n",
       " 'perisheth',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bottomless',\n",
       " 'gulf',\n",
       " 'of',\n",
       " 'his',\n",
       " 'paunch',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'S\",\n",
       " 'PLUTARCH',\n",
       " \"'S\",\n",
       " 'MORALS',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'Indian',\n",
       " 'Sea',\n",
       " 'breedeth',\n",
       " 'the',\n",
       " 'most',\n",
       " 'and',\n",
       " 'the',\n",
       " 'biggest',\n",
       " 'fishes',\n",
       " 'that',\n",
       " 'are',\n",
       " ':',\n",
       " 'among',\n",
       " 'which',\n",
       " 'the',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'Whirlpooles',\n",
       " 'called',\n",
       " 'Balaene',\n",
       " ',',\n",
       " 'take',\n",
       " 'up',\n",
       " 'as',\n",
       " 'much',\n",
       " 'in',\n",
       " 'length',\n",
       " 'as',\n",
       " 'four',\n",
       " 'acres',\n",
       " 'or',\n",
       " 'arpens',\n",
       " 'of',\n",
       " 'land',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'S\",\n",
       " 'PLINY',\n",
       " '.',\n",
       " '``',\n",
       " 'Scarcely',\n",
       " 'had',\n",
       " 'we',\n",
       " 'proceeded',\n",
       " 'two',\n",
       " 'days',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'when',\n",
       " 'about',\n",
       " 'sunrise',\n",
       " 'a',\n",
       " 'great',\n",
       " 'many',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'other',\n",
       " 'monsters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'appeared',\n",
       " '.',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'former',\n",
       " ',',\n",
       " 'one',\n",
       " 'was',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'monstrous',\n",
       " 'size',\n",
       " '.',\n",
       " '...',\n",
       " 'This',\n",
       " 'came',\n",
       " 'towards',\n",
       " 'us',\n",
       " ',',\n",
       " 'open-mouthed',\n",
       " ',',\n",
       " 'raising',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'on',\n",
       " 'all',\n",
       " 'sides',\n",
       " ',',\n",
       " 'and',\n",
       " 'beating',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'before',\n",
       " 'him',\n",
       " 'into',\n",
       " 'a',\n",
       " 'foam',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'S\",\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '``',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'He',\n",
       " 'visited',\n",
       " 'this',\n",
       " 'country',\n",
       " 'also',\n",
       " 'with',\n",
       " 'a',\n",
       " 'view',\n",
       " 'of',\n",
       " 'catching',\n",
       " 'horse-whales',\n",
       " ',',\n",
       " 'which',\n",
       " 'had',\n",
       " 'bones',\n",
       " 'of',\n",
       " 'very',\n",
       " 'great',\n",
       " 'value',\n",
       " 'for',\n",
       " 'their',\n",
       " 'teeth',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'some',\n",
       " 'to',\n",
       " 'the',\n",
       " 'king',\n",
       " '.',\n",
       " '...',\n",
       " 'The',\n",
       " 'best',\n",
       " 'whales',\n",
       " 'were',\n",
       " 'catched',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'country',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'some',\n",
       " 'were',\n",
       " 'forty-eight',\n",
       " ',',\n",
       " 'some',\n",
       " 'fifty',\n",
       " 'yards',\n",
       " 'long',\n",
       " '.',\n",
       " 'He',\n",
       " 'said',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'six',\n",
       " 'who',\n",
       " 'had',\n",
       " 'killed',\n",
       " 'sixty',\n",
       " 'in',\n",
       " 'two',\n",
       " 'days',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'OTHER',\n",
       " 'OR',\n",
       " 'OCTHER',\n",
       " \"'S\",\n",
       " 'VERBAL',\n",
       " 'NARRATIVE',\n",
       " 'TAKEN',\n",
       " 'DOWN',\n",
       " 'FROM',\n",
       " 'HIS',\n",
       " 'MOUTH',\n",
       " 'BY',\n",
       " 'KING',\n",
       " 'ALFRED',\n",
       " ',',\n",
       " 'A.D.',\n",
       " '890',\n",
       " '.',\n",
       " '``',\n",
       " 'And',\n",
       " 'whereas',\n",
       " 'all',\n",
       " 'the',\n",
       " 'other',\n",
       " 'things',\n",
       " ',',\n",
       " 'whether',\n",
       " 'beast',\n",
       " 'or',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254989"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20755"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher',\n",
       " '--',\n",
       " 'threadbare',\n",
       " 'in',\n",
       " 'coat',\n",
       " ',',\n",
       " 'heart',\n",
       " ',',\n",
       " 'body',\n",
       " ',',\n",
       " 'and',\n",
       " 'brain',\n",
       " ';',\n",
       " 'I',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " '.',\n",
       " 'He',\n",
       " 'be',\n",
       " 'ever',\n",
       " 'dust',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and',\n",
       " 'grammars',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'queer',\n",
       " 'handkerchief',\n",
       " ',',\n",
       " 'mockingly',\n",
       " 'embellish',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'gay',\n",
       " 'flag',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'know',\n",
       " 'nations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'He',\n",
       " 'love',\n",
       " 'to',\n",
       " 'dust',\n",
       " 'his',\n",
       " 'old',\n",
       " 'grammars',\n",
       " ';',\n",
       " 'it',\n",
       " 'somehow',\n",
       " 'mildly',\n",
       " 'remind',\n",
       " 'him',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mortality',\n",
       " '.',\n",
       " '``',\n",
       " 'While',\n",
       " 'you',\n",
       " 'take',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'to',\n",
       " 'school',\n",
       " 'others',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'teach',\n",
       " 'them',\n",
       " 'by',\n",
       " 'what',\n",
       " 'name',\n",
       " 'a',\n",
       " 'whale-fish',\n",
       " 'be',\n",
       " 'to',\n",
       " 'be',\n",
       " 'call',\n",
       " 'in',\n",
       " 'our',\n",
       " 'tongue',\n",
       " 'leave',\n",
       " 'out',\n",
       " ',',\n",
       " 'through',\n",
       " 'ignorance',\n",
       " ',',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'H',\n",
       " ',',\n",
       " 'which',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'maketh',\n",
       " 'the',\n",
       " 'signification',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " ',',\n",
       " 'you',\n",
       " 'deliver',\n",
       " 'that',\n",
       " 'which',\n",
       " 'be',\n",
       " 'not',\n",
       " 'true',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " \"''\",\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'Sw.',\n",
       " 'and',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'This',\n",
       " 'animal',\n",
       " 'be',\n",
       " 'name',\n",
       " 'from',\n",
       " 'roundness',\n",
       " 'or',\n",
       " 'roll',\n",
       " ';',\n",
       " 'for',\n",
       " 'in',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'be',\n",
       " 'arch',\n",
       " 'or',\n",
       " 'vault',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " \"WEBSTER'S\",\n",
       " 'DICTIONARY',\n",
       " \"''\",\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'It',\n",
       " 'be',\n",
       " 'more',\n",
       " 'immediately',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Dut',\n",
       " '.',\n",
       " 'and',\n",
       " 'Ger',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A.S.',\n",
       " 'WALW-IAN',\n",
       " ',',\n",
       " 'to',\n",
       " 'roll',\n",
       " ',',\n",
       " 'to',\n",
       " 'wallow',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'S\",\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO-SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE-NUEE-NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE-NUEE-NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Sub-Sub-Librarian',\n",
       " ')',\n",
       " '.',\n",
       " 'It',\n",
       " 'will',\n",
       " 'be',\n",
       " 'see',\n",
       " 'that',\n",
       " 'this',\n",
       " 'mere',\n",
       " 'painstaking',\n",
       " 'burrower',\n",
       " 'and',\n",
       " 'grub-worm',\n",
       " 'of',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub-Sub',\n",
       " 'appear',\n",
       " 'to',\n",
       " 'have',\n",
       " 'go',\n",
       " 'through',\n",
       " 'the',\n",
       " 'long',\n",
       " 'Vaticans',\n",
       " 'and',\n",
       " 'street-stalls',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " ',',\n",
       " 'pick',\n",
       " 'up',\n",
       " 'whatever',\n",
       " 'random',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'whale',\n",
       " 'he',\n",
       " 'could',\n",
       " 'anyways',\n",
       " 'find',\n",
       " 'in',\n",
       " 'any',\n",
       " 'book',\n",
       " 'whatsoever',\n",
       " ',',\n",
       " 'sacred',\n",
       " 'or',\n",
       " 'profane',\n",
       " '.',\n",
       " 'Therefore',\n",
       " 'you',\n",
       " 'must',\n",
       " 'not',\n",
       " ',',\n",
       " 'in',\n",
       " 'every',\n",
       " 'case',\n",
       " 'at',\n",
       " 'least',\n",
       " ',',\n",
       " 'take',\n",
       " 'the',\n",
       " 'higgledy-piggledy',\n",
       " 'whale',\n",
       " 'statements',\n",
       " ',',\n",
       " 'however',\n",
       " 'authentic',\n",
       " ',',\n",
       " 'in',\n",
       " 'these',\n",
       " 'extract',\n",
       " ',',\n",
       " 'for',\n",
       " 'veritable',\n",
       " 'gospel',\n",
       " 'cetology',\n",
       " '.',\n",
       " 'Far',\n",
       " 'from',\n",
       " 'it',\n",
       " '.',\n",
       " 'As',\n",
       " 'touch',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'author',\n",
       " 'generally',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'poets',\n",
       " 'here',\n",
       " 'appear',\n",
       " ',',\n",
       " 'these',\n",
       " 'extract',\n",
       " 'be',\n",
       " 'solely',\n",
       " 'valuable',\n",
       " 'or',\n",
       " 'entertain',\n",
       " ',',\n",
       " 'as',\n",
       " 'afford',\n",
       " 'a',\n",
       " 'glance',\n",
       " 'bird',\n",
       " \"'s\",\n",
       " 'eye',\n",
       " 'view',\n",
       " 'of',\n",
       " 'what',\n",
       " 'have',\n",
       " 'be',\n",
       " 'promiscuously',\n",
       " 'say',\n",
       " ',',\n",
       " 'think',\n",
       " ',',\n",
       " 'fancy',\n",
       " ',',\n",
       " 'and',\n",
       " 'sing',\n",
       " 'of',\n",
       " 'Leviathan',\n",
       " ',',\n",
       " 'by',\n",
       " 'many',\n",
       " 'nations',\n",
       " 'and',\n",
       " 'generations',\n",
       " ',',\n",
       " 'include',\n",
       " 'our',\n",
       " 'own',\n",
       " '.',\n",
       " 'So',\n",
       " 'fare',\n",
       " 'thee',\n",
       " 'well',\n",
       " ',',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub-Sub',\n",
       " ',',\n",
       " 'whose',\n",
       " 'commentator',\n",
       " 'I',\n",
       " 'be',\n",
       " '.',\n",
       " 'Thou',\n",
       " 'belongest',\n",
       " 'to',\n",
       " 'that',\n",
       " 'hopeless',\n",
       " ',',\n",
       " 'sallow',\n",
       " 'tribe',\n",
       " 'which',\n",
       " 'no',\n",
       " 'wine',\n",
       " 'of',\n",
       " 'this',\n",
       " 'world',\n",
       " 'will',\n",
       " 'ever',\n",
       " 'warm',\n",
       " ';',\n",
       " 'and',\n",
       " 'for',\n",
       " 'whom',\n",
       " 'even',\n",
       " 'Pale',\n",
       " 'Sherry',\n",
       " 'would',\n",
       " 'be',\n",
       " 'too',\n",
       " 'rosy-strong',\n",
       " ';',\n",
       " 'but',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'one',\n",
       " 'sometimes',\n",
       " 'love',\n",
       " 'to',\n",
       " 'sit',\n",
       " ',',\n",
       " 'and',\n",
       " 'feel',\n",
       " 'poor-devilish',\n",
       " ',',\n",
       " 'too',\n",
       " ';',\n",
       " 'and',\n",
       " 'grow',\n",
       " 'convivial',\n",
       " 'upon',\n",
       " 'tear',\n",
       " ';',\n",
       " 'and',\n",
       " 'say',\n",
       " 'to',\n",
       " 'them',\n",
       " 'bluntly',\n",
       " ',',\n",
       " 'with',\n",
       " 'full',\n",
       " 'eye',\n",
       " 'and',\n",
       " 'empty',\n",
       " 'glass',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'not',\n",
       " 'altogether',\n",
       " 'unpleasant',\n",
       " 'sadness',\n",
       " '--',\n",
       " 'Give',\n",
       " 'it',\n",
       " 'up',\n",
       " ',',\n",
       " 'Sub-Subs',\n",
       " '!',\n",
       " 'For',\n",
       " 'by',\n",
       " 'how',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'pain',\n",
       " 'ye',\n",
       " 'take',\n",
       " 'to',\n",
       " 'please',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'by',\n",
       " 'so',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'ye',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'go',\n",
       " 'thankless',\n",
       " '!',\n",
       " 'Would',\n",
       " 'that',\n",
       " 'I',\n",
       " 'could',\n",
       " 'clear',\n",
       " 'out',\n",
       " 'Hampton',\n",
       " 'Court',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Tuileries',\n",
       " 'for',\n",
       " 'ye',\n",
       " '!',\n",
       " 'But',\n",
       " 'gulp',\n",
       " 'down',\n",
       " 'your',\n",
       " 'tear',\n",
       " 'and',\n",
       " 'hie',\n",
       " 'aloft',\n",
       " 'to',\n",
       " 'the',\n",
       " 'royal-mast',\n",
       " 'with',\n",
       " 'your',\n",
       " 'hearts',\n",
       " ';',\n",
       " 'for',\n",
       " 'your',\n",
       " 'friends',\n",
       " 'who',\n",
       " 'have',\n",
       " 'go',\n",
       " 'before',\n",
       " 'be',\n",
       " 'clear',\n",
       " 'out',\n",
       " 'the',\n",
       " 'seven-storied',\n",
       " 'heavens',\n",
       " ',',\n",
       " 'and',\n",
       " 'make',\n",
       " 'refugees',\n",
       " 'of',\n",
       " 'long-pampered',\n",
       " 'Gabriel',\n",
       " ',',\n",
       " 'Michael',\n",
       " ',',\n",
       " 'and',\n",
       " 'Raphael',\n",
       " ',',\n",
       " 'against',\n",
       " 'your',\n",
       " 'come',\n",
       " '.',\n",
       " 'Here',\n",
       " 'ye',\n",
       " 'strike',\n",
       " 'but',\n",
       " 'splinter',\n",
       " 'hearts',\n",
       " 'together',\n",
       " '--',\n",
       " 'there',\n",
       " ',',\n",
       " 'ye',\n",
       " 'shall',\n",
       " 'strike',\n",
       " 'unsplinterable',\n",
       " 'glass',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '``',\n",
       " 'And',\n",
       " 'God',\n",
       " 'create',\n",
       " 'great',\n",
       " 'whale',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '``',\n",
       " 'Leviathan',\n",
       " 'maketh',\n",
       " 'a',\n",
       " 'path',\n",
       " 'to',\n",
       " 'shine',\n",
       " 'after',\n",
       " 'him',\n",
       " ';',\n",
       " 'One',\n",
       " 'would',\n",
       " 'think',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'to',\n",
       " 'be',\n",
       " 'hoary',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '``',\n",
       " 'Now',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'have',\n",
       " 'prepare',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fish',\n",
       " 'to',\n",
       " 'swallow',\n",
       " 'up',\n",
       " 'Jonah',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '``',\n",
       " 'There',\n",
       " 'go',\n",
       " 'the',\n",
       " 'ship',\n",
       " ';',\n",
       " 'there',\n",
       " 'be',\n",
       " 'that',\n",
       " 'Leviathan',\n",
       " 'whom',\n",
       " 'thou',\n",
       " 'hast',\n",
       " 'make',\n",
       " 'to',\n",
       " 'play',\n",
       " 'therein',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '``',\n",
       " 'In',\n",
       " 'that',\n",
       " 'day',\n",
       " ',',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'with',\n",
       " 'his',\n",
       " 'sore',\n",
       " ',',\n",
       " 'and',\n",
       " 'great',\n",
       " ',',\n",
       " 'and',\n",
       " 'strong',\n",
       " 'sword',\n",
       " ',',\n",
       " 'shall',\n",
       " 'punish',\n",
       " 'Leviathan',\n",
       " 'the',\n",
       " 'pierce',\n",
       " 'serpent',\n",
       " ',',\n",
       " 'even',\n",
       " 'Leviathan',\n",
       " 'that',\n",
       " 'crook',\n",
       " 'serpent',\n",
       " ';',\n",
       " 'and',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'slay',\n",
       " 'the',\n",
       " 'dragon',\n",
       " 'that',\n",
       " 'be',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sea',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " \"''\",\n",
       " 'And',\n",
       " 'what',\n",
       " 'thing',\n",
       " 'soever',\n",
       " 'besides',\n",
       " 'cometh',\n",
       " 'within',\n",
       " 'the',\n",
       " 'chaos',\n",
       " 'of',\n",
       " 'this',\n",
       " 'monster',\n",
       " \"'s\",\n",
       " 'mouth',\n",
       " ',',\n",
       " 'be',\n",
       " 'it',\n",
       " 'beast',\n",
       " ',',\n",
       " 'boat',\n",
       " ',',\n",
       " 'or',\n",
       " 'stone',\n",
       " ',',\n",
       " 'down',\n",
       " 'it',\n",
       " 'go',\n",
       " 'all',\n",
       " 'incontinently',\n",
       " 'that',\n",
       " 'foul',\n",
       " 'great',\n",
       " 'swallow',\n",
       " 'of',\n",
       " 'his',\n",
       " ',',\n",
       " 'and',\n",
       " 'perisheth',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bottomless',\n",
       " 'gulf',\n",
       " 'of',\n",
       " 'his',\n",
       " 'paunch',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'S\",\n",
       " 'PLUTARCH',\n",
       " \"'S\",\n",
       " 'MORALS',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'Indian',\n",
       " 'Sea',\n",
       " 'breedeth',\n",
       " 'the',\n",
       " 'most',\n",
       " 'and',\n",
       " 'the',\n",
       " 'biggest',\n",
       " 'fish',\n",
       " 'that',\n",
       " 'be',\n",
       " ':',\n",
       " 'among',\n",
       " 'which',\n",
       " 'the',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'Whirlpooles',\n",
       " 'call',\n",
       " 'Balaene',\n",
       " ',',\n",
       " 'take',\n",
       " 'up',\n",
       " 'as',\n",
       " 'much',\n",
       " 'in',\n",
       " 'length',\n",
       " 'as',\n",
       " 'four',\n",
       " 'acres',\n",
       " 'or',\n",
       " 'arpens',\n",
       " 'of',\n",
       " 'land',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'S\",\n",
       " 'PLINY',\n",
       " '.',\n",
       " '``',\n",
       " 'Scarcely',\n",
       " 'have',\n",
       " 'we',\n",
       " 'proceed',\n",
       " 'two',\n",
       " 'days',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'when',\n",
       " 'about',\n",
       " 'sunrise',\n",
       " 'a',\n",
       " 'great',\n",
       " 'many',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'other',\n",
       " 'monsters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'appear',\n",
       " '.',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'former',\n",
       " ',',\n",
       " 'one',\n",
       " 'be',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'monstrous',\n",
       " 'size',\n",
       " '.',\n",
       " '...',\n",
       " 'This',\n",
       " 'come',\n",
       " 'towards',\n",
       " 'us',\n",
       " ',',\n",
       " 'open-mouthed',\n",
       " ',',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'wave',\n",
       " 'on',\n",
       " 'all',\n",
       " 'side',\n",
       " ',',\n",
       " 'and',\n",
       " 'beat',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'before',\n",
       " 'him',\n",
       " 'into',\n",
       " 'a',\n",
       " 'foam',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'S\",\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '``',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'He',\n",
       " 'visit',\n",
       " 'this',\n",
       " 'country',\n",
       " 'also',\n",
       " 'with',\n",
       " 'a',\n",
       " 'view',\n",
       " 'of',\n",
       " 'catch',\n",
       " 'horse-whales',\n",
       " ',',\n",
       " 'which',\n",
       " 'have',\n",
       " 'bone',\n",
       " 'of',\n",
       " 'very',\n",
       " 'great',\n",
       " 'value',\n",
       " 'for',\n",
       " 'their',\n",
       " 'teeth',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'he',\n",
       " 'bring',\n",
       " 'some',\n",
       " 'to',\n",
       " 'the',\n",
       " 'king',\n",
       " '.',\n",
       " '...',\n",
       " 'The',\n",
       " 'best',\n",
       " 'whale',\n",
       " 'be',\n",
       " 'catch',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'country',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'some',\n",
       " 'be',\n",
       " 'forty-eight',\n",
       " ',',\n",
       " 'some',\n",
       " 'fifty',\n",
       " 'yards',\n",
       " 'long',\n",
       " '.',\n",
       " 'He',\n",
       " 'say',\n",
       " 'that',\n",
       " 'he',\n",
       " 'be',\n",
       " 'one',\n",
       " 'of',\n",
       " 'six',\n",
       " 'who',\n",
       " 'have',\n",
       " 'kill',\n",
       " 'sixty',\n",
       " 'in',\n",
       " 'two',\n",
       " 'days',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'OTHER',\n",
       " 'OR',\n",
       " 'OCTHER',\n",
       " \"'S\",\n",
       " 'VERBAL',\n",
       " 'NARRATIVE',\n",
       " 'TAKEN',\n",
       " 'DOWN',\n",
       " 'FROM',\n",
       " 'HIS',\n",
       " 'MOUTH',\n",
       " 'BY',\n",
       " 'KING',\n",
       " 'ALFRED',\n",
       " ',',\n",
       " 'A.D.',\n",
       " '890',\n",
       " '.',\n",
       " '``',\n",
       " 'And',\n",
       " 'whereas',\n",
       " 'all',\n",
       " 'the',\n",
       " 'other',\n",
       " 'things',\n",
       " ',',\n",
       " 'whether',\n",
       " 'beast',\n",
       " 'or',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return lemmatized\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    words=moby_tokens\n",
    "    uni_words=set(words)\n",
    "    \n",
    "    return (len(uni_words))/(len(words))\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125668166077752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.probability import FreqDist\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    words=text1\n",
    "   #lemmatized = [lemmatizer.lemmatize(w,'v') for w in words]\n",
    "    low_words=[w.lower() for w in words]\n",
    "    word_frq=FreqDist(words)\n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return ((word_frq['Whale']+word_frq['whale'])/len(low_words))*100\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.probability import FreqDist\n",
    "    words=text1\n",
    "    \n",
    "    word_frq=FreqDist(words)\n",
    "    \n",
    "    sor_fre=sorted(word_frq.items(),key= lambda x: (x[1],[0]) ,reverse=True)\n",
    "    \n",
    "    \n",
    "    return sor_fre[:20]\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    from nltk.probability import FreqDist\n",
    "    words=text1\n",
    "    word_frq=FreqDist(words)\n",
    "    \n",
    "    words_5=[w for w in word_frq.keys() if len(w) > 5 and word_frq[w] >150 ]\n",
    "    sort_word=sorted(words_5)\n",
    "    \n",
    "    return sort_word\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    words=text1\n",
    "    \n",
    "    sort_len=sorted(words,key= lambda x: len(x),reverse=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (sort_len[0],len(sort_len[0]))\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    from nltk.probability import FreqDist\n",
    "    words=text1\n",
    "    word_frq=FreqDist(words)\n",
    "    li=[w for w in word_frq.keys() if w.isalpha()==True and word_frq[w]>2000]\n",
    "    li2=[]\n",
    "    for w in li:\n",
    "        li2.append((word_frq[w],w))\n",
    "        \n",
    "    sor_fre=sorted(li2,key= lambda x: (x[0],[1]) ,reverse=True)\n",
    "        \n",
    "    return sor_fre\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.881952902963864"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    \n",
    "    sentance_li=nltk.sent_tokenize(moby_raw)\n",
    "    sen_len=np.array([len(nltk.word_tokenize(w)) for w in sentance_li])\n",
    "    \n",
    "    return np.average(sen_len)\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oh!', 25), ('Ha!', 10), ('\"Oh!', 9), ('...', 7), ('Ah!', 6)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.probability import FreqDist\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    sentance_li=nltk.sent_tokenize(moby_raw)\n",
    "    lemmatized = [lemmatizer.lemmatize(w) for w in sentance_li]\n",
    "    sen_frq=FreqDist(lemmatized)\n",
    "    \n",
    "    \n",
    "    return sen_frq.most_common(5)\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import (\n",
    "    edit_distance,\n",
    "    jaccard_distance,\n",
    "    )\n",
    "from nltk.util import ngrams\n",
    "correct_spellings = words.words()\n",
    "spellings_series = pd.Series(correct_spellings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(entries, gram_number):\n",
    "    \"\"\"find the closet words to each entry\n",
    "\n",
    "    Args:\n",
    "     entries: collection of words to match\n",
    "     gram_number: number of n-grams to use\n",
    "\n",
    "    Returns:\n",
    "     list: words with the closest jaccard distance to entries\n",
    "    \"\"\"\n",
    "    outcomes = []\n",
    "    for entry in entries:\n",
    "        spellings = spellings_series[spellings_series.str.startswith(entry[0])]\n",
    "        distances = ((jaccard_distance(set(ngrams(entry, gram_number)),\n",
    "                                       set(ngrams(word, gram_number))), word)\n",
    "                     for word in spellings)\n",
    "        closest = min(distances)\n",
    "        outcomes.append(closest[1])\n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return jaccard(entries, 3)\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return jaccard(entries, 4)\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e367a4e4571c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0manswer_eleven\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-e367a4e4571c>\u001b[0m in \u001b[0;36manswer_eleven\u001b[0;34m(entries)\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     word), word)\n\u001b[1;32m      7\u001b[0m                      for word in correct_spellings)\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mclosest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moutcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-e367a4e4571c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m         distances = ((edit_distance(entry,\n\u001b[1;32m      6\u001b[0m                                     word), word)\n\u001b[0;32m----> 7\u001b[0;31m                      for word in correct_spellings)\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mclosest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/metrics/distance.py\u001b[0m in \u001b[0;36medit_distance\u001b[0;34m(s1, s2, substitution_cost, transpositions)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             _edit_dist_step(lev, i + 1, j + 1, s1, s2,\n\u001b[0;32m---> 91\u001b[0;31m                             substitution_cost=substitution_cost, transpositions=transpositions)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/metrics/distance.py\u001b[0m in \u001b[0;36m_edit_dist_step\u001b[0;34m(lev, i, j, s1, s2, substitution_cost, transpositions)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# transposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# never picked by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtranspositions\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    outcomes = []\n",
    "    for entry in entries:\n",
    "        distances = ((edit_distance(entry,\n",
    "                                    word), word)\n",
    "                     for word in correct_spellings)\n",
    "        closest = min(distances)\n",
    "        outcomes.append(closest[1])\n",
    "    return outcomes\n",
    "    \n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
